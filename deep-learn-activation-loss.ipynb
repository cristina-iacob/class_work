{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot code your target variable using the `to_categorical()` function from the `keras.utils` module\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. In this task, you'll implement several ANN models with different activation functions. Specifically, do the following:\n",
    "\n",
    "* Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0333 - accuracy: 0.7460\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5208 - accuracy: 0.8709s - loss: 0.5599 - ac\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.4209 - accuracy: 0.8886\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3743 - accuracy: 0.8977\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3455 - accuracy: 0.9042\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3251 - accuracy: 0.9088\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3094 - accuracy: 0.9126\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2965 - accuracy: 0.9160\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2856 - accuracy: 0.9187\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2760 - accuracy: 0.9212\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2673 - accuracy: 0.9238\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2594 - accuracy: 0.9259\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2521 - accuracy: 0.9281\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2452 - accuracy: 0.9296\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2388 - accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2327 - accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2270 - accuracy: 0.9357\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2215 - accuracy: 0.9368\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2164 - accuracy: 0.9386\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2114 - accuracy: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9d9e67b90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_model = Sequential()\n",
    "# our first dense layer\n",
    "tanh_model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
    "# our second dense layer\n",
    "tanh_model.add(Dense(64, activation=\"tanh\"))\n",
    "# last layer is the output layer.\n",
    "tanh_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "tanh_model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "tanh_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tanh_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.2088997276455164\n",
      "Test accuracy: 0.9412\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = tanh_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2943 - accuracy: 0.1646\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 2.2352 - accuracy: 0.3303\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 2.1753 - accuracy: 0.4966\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 2.0908 - accuracy: 0.5769\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.9678 - accuracy: 0.6114\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.7995 - accuracy: 0.6347\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.6010 - accuracy: 0.6593\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.4066 - accuracy: 0.6844\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.2421 - accuracy: 0.7081\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.1120 - accuracy: 0.7310\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.0102 - accuracy: 0.7514\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9290 - accuracy: 0.7689\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8626 - accuracy: 0.7836\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.8069 - accuracy: 0.7972\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.7590 - accuracy: 0.8076\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7171 - accuracy: 0.8192\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.6803 - accuracy: 0.8278\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.6478 - accuracy: 0.8346\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.6189 - accuracy: 0.8421\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5931 - accuracy: 0.8474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9c9b88c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_model = Sequential()\n",
    "# our first dense layer\n",
    "sig_model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
    "# our second dense layer\n",
    "sig_model.add(Dense(64, activation=\"sigmoid\"))\n",
    "# last layer is the output layer.\n",
    "sig_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "sig_model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "sig_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sig_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.5682575039863587\n",
      "Test accuracy: 0.8565\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = sig_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "relu_model = Sequential()\n",
    "\n",
    "relu_model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "relu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2247 - accuracy: 0.6756\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.4986 - accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3872 - accuracy: 0.8919\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3402 - accuracy: 0.9036\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3120 - accuracy: 0.9115\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2913 - accuracy: 0.9168\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2750 - accuracy: 0.9214\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2611 - accuracy: 0.9252\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2492 - accuracy: 0.9287\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2385 - accuracy: 0.9314\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2287 - accuracy: 0.9344\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2200 - accuracy: 0.9372\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2118 - accuracy: 0.9396\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2043 - accuracy: 0.9413\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1972 - accuracy: 0.9433\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1907 - accuracy: 0.9453\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1844 - accuracy: 0.9476\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1788 - accuracy: 0.9490\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1734 - accuracy: 0.9505\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1683 - accuracy: 0.9517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9da0b8bd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "relu_model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "relu_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16815965002402664\n",
      "Test accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = relu_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tanh = 94%\n",
    "* sigmoid = 86%\n",
    "* reLU = 95%\n",
    "\n",
    "The reLU model performed the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. In this task, you'll implement the ANN models specified below. For each, use the hinge loss function as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9905 - accuracy: 0.4075\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7830 - accuracy: 0.6694\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.6031 - accuracy: 0.7951\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.4744 - accuracy: 0.8434\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3946 - accuracy: 0.8637\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3457 - accuracy: 0.8748\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3133 - accuracy: 0.8827\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2901 - accuracy: 0.8887\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2725 - accuracy: 0.8938\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2585 - accuracy: 0.8978\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2471 - accuracy: 0.9015\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2374 - accuracy: 0.9043\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2292 - accuracy: 0.9068\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2220 - accuracy: 0.9089\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2156 - accuracy: 0.9111\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2099 - accuracy: 0.9129\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2047 - accuracy: 0.9146\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2001 - accuracy: 0.9161\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1957 - accuracy: 0.9179\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1917 - accuracy: 0.9197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9da2c9810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "tanh_model = Sequential()\n",
    "\n",
    "tanh_model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
    "tanh_model.add(Dense(64, activation=\"tanh\"))\n",
    "tanh_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "tanh_model.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "tanh_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.18412239052653312\n",
      "Test accuracy: 0.9228\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = tanh_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0183 - accuracy: 0.1598\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0029 - accuracy: 0.1968\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.0022 - accuracy: 0.2487\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.0016 - accuracy: 0.3076\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0011 - accuracy: 0.3643\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0006 - accuracy: 0.4105\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.0002 - accuracy: 0.4462\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9998 - accuracy: 0.4756\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9994 - accuracy: 0.5007\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9990 - accuracy: 0.5213\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9987 - accuracy: 0.5403\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9984 - accuracy: 0.5575\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9980 - accuracy: 0.5740\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9977 - accuracy: 0.5867\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9974 - accuracy: 0.6009\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9971 - accuracy: 0.6100\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9967 - accuracy: 0.6201\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9964 - accuracy: 0.6302\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9961 - accuracy: 0.6372\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9958 - accuracy: 0.6457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9da403fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "sig_model = Sequential()\n",
    "\n",
    "sig_model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
    "sig_model.add(Dense(64, activation=\"sigmoid\"))\n",
    "sig_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "sig_model.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "sig_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9955600111007691\n",
      "Test accuracy: 0.6541\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = sig_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0128 - accuracy: 0.2975\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9793 - accuracy: 0.5103\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8938 - accuracy: 0.5912\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7352 - accuracy: 0.6821\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.5554 - accuracy: 0.7706\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.4334 - accuracy: 0.8490\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3501 - accuracy: 0.8763\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.3005 - accuracy: 0.8866\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2699 - accuracy: 0.8940\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2492 - accuracy: 0.8994\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2338 - accuracy: 0.9039\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2216 - accuracy: 0.9079\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2119 - accuracy: 0.9101\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2036 - accuracy: 0.9137\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1964 - accuracy: 0.9162\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1901 - accuracy: 0.9184\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1846 - accuracy: 0.9205\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1797 - accuracy: 0.9224\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1751 - accuracy: 0.9239\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1710 - accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9da3b6f50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "relu_model = Sequential()\n",
    "\n",
    "relu_model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "relu_model.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "relu_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1635830114901066\n",
      "Test accuracy: 0.9291\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = relu_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the results of each model with the result of the same model from the previous task. Which loss function performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With crossentropy loss:\n",
    "* tanh = 94%\n",
    "* sigmoid = 86%\n",
    "* reLU = 95%\n",
    "\n",
    "With hinge loss:\n",
    "* tanh = 92%\n",
    "* sigmoid = 66%\n",
    "* reLU = 92%\n",
    "\n",
    "* All 3 activation types performed worse using hinge loss\n",
    "* tanh and reLU performed the best using either crossentropy or hinge loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
